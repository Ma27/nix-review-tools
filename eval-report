#!/usr/bin/env nix-shell

#
# Given data, make a section
#
def table(data, name:)
  puts "### #{name}\n"
  puts ""
  puts " * #{data.count} issues"
  puts "<details><summary>Failure table</summary>"
  puts "<table>"
  puts "<thead><tr>"
  puts "<th>job</th>"
  puts "<th>status</th>"
  puts "</tr></thead>"
  data.each do |job|
    puts "<tr>"
    puts "<td><tt><a href='#{job[:job]}'>#{job[:name]}</a></tt></td>"
    puts "<td>#{job[:status]}</td>"
    puts "</tr>"
  end
  puts "</table>"
  puts "</details>"
  puts "\n"
end

#
# Conditionally downloads, then parses the file.
#

abort "Usage: eval-report <id>" unless ARGV[0]

FILE = ARGV[0] + ".html"

unless File.exists?(FILE)
  `curl -o "#{FILE}" "https://hydra.nixos.org/eval/#{ARGV[0]}?full=1"`
end

contents = File.read(FILE)
  .split(/<\/?tbody>/)
  .select { |txt| txt.split("\n").first.match(/^\s*<tr>\s+<td>/) }
  .join("\n")
  .split("<tr>")[2..-1]
  .map do |row|
    row.split("</tr>").first
  end
  .map do |raw|
    status = raw.split('title="', 2).last.split('"', 2).first
    job_parts = raw.split('<a href="', 2).last.split('</a>', 2).first
    job = job_parts.split('"', 2).first
    name = job_parts.split('">', 2).last.split("</td>", 2).first
    platform = raw.split('td class="nowrap"><tt>', 2).last.split('</tt>', 2).first

    {
      platform: platform,
      job: job,
      name: name,
      status: status,
      raw: raw,
    }
  end

IGNORED = ["Succeeded", "Queued"]
not_a_success = contents.reject { |job| IGNORED.include?(job[:status]) }
queued = contents.select { |job| ["Queued"].include?(job[:status]) }

#
# Here, we have the actual markdown...
#

indexed = not_a_success.reduce({}) do |hash, j|
  hash[j[:platform]] ||= []
  hash[j[:platform]] << j
  hash
end

indexed.each do |p, jobs|
  table(jobs, name: p)
end

table(queued, name: "Still queued")

#!nix-shell -p curl -p ruby -i ruby
# vim: set ft=ruby:
